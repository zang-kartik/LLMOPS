
# **Tools for LLMOps**

1. **Stanford Alpaca 7B** -> A model fine-tuned from the LLaMA 7B model, on 52k instruction following demonstration. Alpaca behaves qualitatively similar to OpenAI' text-davinci-003, while being surprisingly easy and cheap to reproduce.

2. **BLOOM** ->  Bloom is a autoregressive LLM trained to continue text from a prompt on vast amounts of text data using industrial scale computational scale. Bloom can also be instructed to perform text tasks it hasn't been explicitly trained for, by casting them as text generation task. It is a transformer based model, developed by bigscience, funded by hugging face. 

3. **Dolly** -> Dolly is a instruction following large language model,trained on databricks ML platform,that is licensed for commercial use. Dolly is trained on ~15k instruction/response fine tuning records generated by databricks employees in capability domains from InstructGPT paper, including brainstorming, classification, closed QA, generation, information extraction, open QA and summarization.
4.  

